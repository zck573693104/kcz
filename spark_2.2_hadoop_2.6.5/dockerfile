FROM centos:centos6.6
MAINTAINER zck

COPY phoenix-5.0.0.tar.gz /usr/local
COPY hive-2.3.4.tar.gz /usr/local
COPY mysql-5.6.43.tar.gz /usr/local
ADD jdk-8u191-linux-x64.tar.gz /usr/java/
ADD spark-2.2.2-bin-hadoop2.6.tgz /usr/local/
ADD hadoop-2.6.5.tar.gz /usr/local
ADD zookeeper-3.4.13.tar.gz /usr/local
ADD kafka_2.11-2.1.0.tgz /usr/local
ADD hbase-2.0.5-bin.tar.gz /usr/local
ADD sqoop-1.99.7-bin-hadoop200.tar.gz /usr/local
COPY bootstrap.sh /etc/bootstrap.sh
COPY mysql.sh /usr/local

RUN yum install -y wget \
 && wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-6.repo \
 && yum clean all \
 && yum makecache \
 && yum -y update \
 && yum install -y unzip python3 python3-setuptools  numactl libaio tar \
 && mkdir -p /usr/local/mysql-5.6.43 && tar -zxvf /usr/local/mysql-5.6.43.tar.gz -C /usr/local/mysql-5.6.43 --strip-components 1 \
 && mkdir -p /usr/local/phoenix-5.0.0 && tar -zxvf /usr/local/phoenix-5.0.0.tar.gz -C /usr/local/phoenix-5.0.0 --strip-components 1 \
 && mkdir -p /usr/local/hive-2.3.4 && tar -zxvf /usr/local/hive-2.3.4.tar.gz -C /usr/local/hive-2.3.4 --strip-components 1 \
 && yum install -y net-tools \
 && yum -y install bzip2 zip gzip\
 && yum install -y vim curl openssh-server openssh-clients \
 && ssh-keygen -q -t rsa -b 2048 -f /etc/ssh/ssh_host_rsa_key -N '' \
 && ssh-keygen -f /root/.ssh/id_rsa -N '' \
 && touch /root/.ssh/authorized_keys \
 && cat /root/.ssh/id_rsa.pub >> /root/.ssh/authorized_keys \
 && sed -i 's/#PermitRootLogin  without-password/PermitRootLogin yes/g' /etc/ssh/sshd_config \
 && sed -i 's/#   StrictHostKeyChecking ask/StrictHostKeyChecking no/g' /etc/ssh/ssh_config \
 && echo "root:123456" | chpasswd \
 && rm -rf /var/lib/apt/lists/* \
 && rm -rf /etc/my.cnf \
 && mkdir -p /data/mysql \
 && chown -R root:root /usr/local/mysql-5.6.43 \
 && chown root.root /etc/bootstrap.sh \
 && chmod 700 /etc/bootstrap.sh \
 && chmod 700 /usr/local/mysql.sh



COPY mysql_init.sql /usr/local
COPY my.cnf /etc


# http://blog.stuart.axelbrooke.com/python-3-on-spark-return-of-the-pythonhashseed
ENV PYTHONHASHSEED 0
ENV PYTHONIOENCODING UTF-8
ENV PIP_DISABLE_PIP_VERSION_CHECK 1

# JAVA
ARG JAVA_MAJOR_VERSION=8
ARG JAVA_UPDATE_VERSION=191
ARG JAVA_BUILD_NUMBER=12
ENV JAVA_HOME /usr/java/jdk1.${JAVA_MAJOR_VERSION}.0_${JAVA_UPDATE_VERSION}
ENV PATH $PATH:$JAVA_HOME/bin

# ZK KAFKA
ENV ZOOKEEPER_HOME=/usr/local/zookeeper-3.4.13
ENV PATH=$PATH:$ZOOKEEPER_HOME/bin
ENV KAFKA_HOME=/usr/local/kafka_2.11-2.1.0
ENV PATH=$PATH:$KAFKA_HOME/bin

# HADOOP
ENV HADOOP_VERSION 2.6.5
ENV HADOOP_HOME /usr/local/hadoop-$HADOOP_VERSION
ENV HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
ENV HADOOP_COMMON_HOME=$HADOOP_HOME
ENV PATH $PATH:$HADOOP_HOME/bin

#HIVE
ENV HIVE_VERSION 2.3.4
ENV HIVE_HOME /usr/local/hive-$HIVE_VERSION
ENV HIVE_COMMON_HOME=$HIVE_HOME
ENV PATH $PATH:$HIVE_HOME/bin

#HBASE
ENV HBASE_VERSION 2.0.5
ENV HBASE_HOME /usr/local/hbase-$HBASE_VERSION
ENV HBASE_COMMON_HOME=$HBASE_HOME
ENV PATH $PATH:$HBASE_HOME/bin


# SPARK
ENV SPARK_VERSION 2.2.2-bin-hadoop2.6
ENV SPARK_PACKAGE spark-${SPARK_VERSION}-bin-without-hadoop
ENV SPARK_HOME /usr/local/spark-${SPARK_VERSION}
ENV SPARK_DIST_CLASSPATH="$HADOOP_HOME/etc/hadoop/*:$HADOOP_HOME/share/hadoop/common/lib/*:$HADOOP_HOME/share/hadoop/common/*:$HADOOP_HOME/share/hadoop/hdfs/*:$HADOOP_HOME/share/hadoop/hdfs/lib/*:$HADOOP_HOME/share/hadoop/hdfs/*:$HADOOP_HOME/share/hadoop/yarn/lib/*:$HADOOP_HOME/share/hadoop/yarn/*:$HADOOP_HOME/share/hadoop/mapreduce/lib/*:$HADOOP_HOME/share/hadoop/mapreduce/*:$HADOOP_HOME/share/hadoop/tools/lib/*"
ENV PATH $PATH:${SPARK_HOME}/bin

#PHOENIX
ENV PHOENIX_VERSION 5.0.0
ENV PHOENIX_HOME /usr/local/phoenix-$PHOENIX_VERSION
ENV PHOENIX_COMMON_HOME=$PHOENIX_HOME
ENV PATH $PATH:$PHOENIX_HOME/bin

#SQOOP
ENV SQOOP_VERSION 1.99.7
ENV SQOOP_HOME /usr/local/sqoop-{$SQOOP_VERSION}-bin-hadoop200
ENV PATH $PATH:$SQOOP_HOME/

#MYSQL
ENV MYSQL_VERSION 5.6.43
ENV MYSQL_HOME /usr/local/mysql-$MYSQL_VERSION
ENV PATH $PATH:$MYSQL_HOME/bin


RUN  rm $HADOOP_HOME/etc/hadoop/hadoop-env.sh \
 &&	rm $HADOOP_HOME/etc/hadoop/yarn-env.sh \
 &&	rm $HADOOP_HOME/etc/hadoop/core-site.xml \
 &&	rm $HADOOP_HOME/etc/hadoop/hdfs-site.xml \
 &&	rm $HADOOP_HOME/etc/hadoop/yarn-site.xml \
 &&	rm $HADOOP_HOME/etc/hadoop/slaves \
 && rm $SPARK_HOME/sbin/spark-config.sh \
 && sed -i 's/localhost/master/g' /usr/local/kafka_2.11-2.1.0/config/server.properties \
 && mkdir -p /usr/hbase \
 && mkdir -p /usr/tmp \
 && mkdir -p /usr/pids \
 && rm -rf $HBASE_HOME/conf/hbase-site.xml \
 && rm -rf $HBASE_HOME/conf/regionservers \
 && rm -rf $HBASE_HOME/conf/hbase-env.sh \
 && rm -rf $HADOOP_HOME/share/hadoop/yarn/lib/jline-0.9.94.jar \
 && cp $HIVE_HOME/lib/jline-2.12.jar $HADOOP_HOME/share/hadoop/yarn/lib/ \
 && cp /usr/local/phoenix-5.0.0/phoenix-core-5.0.0-HBase-2.0.jar /usr/local/hbase-2.0.5/lib/ \
 && cp /usr/local/phoenix-5.0.0/phoenix-5.0.0-HBase-2.0-server.jar /usr/local/hbase-2.0.5/lib/
COPY hive-site.xml $HIVE_COMMON_HOME/conf/
COPY hive-env.sh $HIVE_COMMON_HOME/conf/
COPY hive-log4j2.properties $HIVE_COMMON_HOME/conf/
COPY core-site.xml $HADOOP_HOME/etc/hadoop/
COPY hdfs-site.xml $HADOOP_HOME/etc/hadoop/
COPY hadoop-env.sh $HADOOP_HOME/etc/hadoop/
COPY yarn-env.sh $HADOOP_HOME/etc/hadoop/
COPY slaves $HADOOP_HOME/etc/hadoop/
COPY mapred-site.xml $HADOOP_HOME/etc/hadoop/
COPY yarn-site.xml $HADOOP_HOME/etc/hadoop/
COPY spark-env.sh $SPARK_HOME/conf/
COPY run.sh /usr/local/
COPY initRun.sh /usr/local/
COPY zoo.cfg $ZOOKEEPER_HOME/conf/
COPY KafkaOffsetMonitor-assembly-0.2.0.jar $KAFKA_HOME
COPY kafka-monitor-start.sh $KAFKA_HOME
COPY hbase-site.xml $HBASE_HOME/conf
COPY regionservers $HBASE_HOME/conf
COPY hbase-env.sh $HBASE_HOME/conf
COPY sqoop-env.sh $SQOOP_HOME/conf
COPY mysql-connector-java-5.1.35.jar $HIVE_HOME/lib
COPY json-serde-1.3.6-jar-with-dependencies.jar $HIVE_HOME/lib
COPY mysql-connector-java-5.1.35.jar $SQOOP_HOME/lib
COPY mysql.server /etc/init.d/mysql
WORKDIR $SPARK_HOME
CMD ["bin/spark-class", "org.apache.spark.deploy.master.Master"]
ENTRYPOINT ["/etc/bootstrap.sh"]