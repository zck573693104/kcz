FROM centos:centos6.6
MAINTAINER zck

RUN yum install -y wget \
 && wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-6.repo \
 && yum clean all \
 && yum makecache \
 && yum -y update \
 && yum install -y curl unzip python3 python3-setuptools \
 && yum install -y net-tools \
 && yum -y install bzip2 zip gzip\
 && yum install -y tar \
 && yum install -y vim curl openssh-server openssh-clients\
 && ssh-keygen -q -t rsa -b 2048 -f /etc/ssh/ssh_host_rsa_key -N '' \
 && ssh-keygen -f /root/.ssh/id_rsa -N '' \
 && touch /root/.ssh/authorized_keys \
 && cat /root/.ssh/id_rsa.pub >> /root/.ssh/authorized_keys \
 && sed -i 's/#PermitRootLogin  without-password/PermitRootLogin yes/g' /etc/ssh/sshd_config \
 && sed -i 's/#   StrictHostKeyChecking ask/StrictHostKeyChecking no/g' /etc/ssh/ssh_config \
 && echo "root:123456" | chpasswd \	
 && rm -rf /var/lib/apt/lists/*

COPY bootstrap.sh /etc/bootstrap.sh
RUN chown root.root /etc/bootstrap.sh \
 && chmod 700 /etc/bootstrap.sh

# http://blog.stuart.axelbrooke.com/python-3-on-spark-return-of-the-pythonhashseed
ENV PYTHONHASHSEED 0
ENV PYTHONIOENCODING UTF-8
ENV PIP_DISABLE_PIP_VERSION_CHECK 1
ADD jdk-8u191-linux-x64.tar.gz /usr/java/
ADD spark-2.2.2-bin-hadoop2.6.tgz /usr/local/
ADD hadoop-2.6.5.tar.gz /usr/local
# JAVA
ARG JAVA_MAJOR_VERSION=8
ARG JAVA_UPDATE_VERSION=191
ARG JAVA_BUILD_NUMBER=12
ENV JAVA_HOME /usr/java/jdk1.${JAVA_MAJOR_VERSION}.0_${JAVA_UPDATE_VERSION}
ENV PATH $PATH:$JAVA_HOME/bin

# HADOOP
ENV HADOOP_VERSION 2.6.5
ENV HADOOP_HOME /usr/local/hadoop-$HADOOP_VERSION
ENV HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
ENV HADOOP_COMMON_HOME=$HADOOP_HOME
ENV PATH $PATH:$HADOOP_HOME/bin

# SPARK
ENV SPARK_VERSION 2.2.2-bin-hadoop2.6
ENV SPARK_PACKAGE spark-${SPARK_VERSION}-bin-without-hadoop
ENV SPARK_HOME /usr/local/spark-${SPARK_VERSION}
ENV SPARK_DIST_CLASSPATH="$HADOOP_HOME/etc/hadoop/*:$HADOOP_HOME/share/hadoop/common/lib/*:$HADOOP_HOME/share/hadoop/common/*:$HADOOP_HOME/share/hadoop/hdfs/*:$HADOOP_HOME/share/hadoop/hdfs/lib/*:$HADOOP_HOME/share/hadoop/hdfs/*:$HADOOP_HOME/share/hadoop/yarn/lib/*:$HADOOP_HOME/share/hadoop/yarn/*:$HADOOP_HOME/share/hadoop/mapreduce/lib/*:$HADOOP_HOME/share/hadoop/mapreduce/*:$HADOOP_HOME/share/hadoop/tools/lib/*"
ENV PATH $PATH:${SPARK_HOME}/bin

RUN  rm $HADOOP_HOME/etc/hadoop/hadoop-env.sh \
 &&	rm $HADOOP_HOME/etc/hadoop/yarn-env.sh \
 &&	rm $HADOOP_HOME/etc/hadoop/core-site.xml \
 &&	rm $HADOOP_HOME/etc/hadoop/hdfs-site.xml \
 &&	rm $HADOOP_HOME/etc/hadoop/yarn-site.xml \
 &&	rm $HADOOP_HOME/etc/hadoop/slaves \
 && rm $SPARK_HOME/sbin/spark-config.sh
COPY core-site.xml $HADOOP_HOME/etc/hadoop/
COPY hdfs-site.xml $HADOOP_HOME/etc/hadoop/
COPY hadoop-env.sh $HADOOP_HOME/etc/hadoop/
COPY yarn-env.sh $HADOOP_HOME/etc/hadoop/
COPY slaves $HADOOP_HOME/etc/hadoop/
COPY mapred-site.xml $HADOOP_HOME/etc/hadoop/
COPY yarn-site.xml $HADOOP_HOME/etc/hadoop/
COPY spark-env.sh $SPARK_HOME/conf/
WORKDIR $SPARK_HOME
CMD ["bin/spark-class", "org.apache.spark.deploy.master.Master"]
ENTRYPOINT ["/etc/bootstrap.sh"]

